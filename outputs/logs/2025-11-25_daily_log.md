## 2025-11-25 实验日志

1. **ResNet50 训练脚本修正与运行**  
   - 修复 `src/training/resnet50_baseline.py` 的日志写入字段、预测文件字段不匹配问题，确保训练全流程（冻结 → 微调 → 测试）能顺利完成。  

2. **E2：无增强基线 (ResNet50, AdamW)**  
   - 配置：`--augment none`, `freeze=5`, `finetune=15`, `batch_size=16`, `lr_head=1e-3`, `lr_backbone=1e-4`, Cosine LR。  
   - 结果：验证集 `macro-F1 ≈ 0.646`（最佳 epoch 6），`val_acc ≈ 0.664`；测试集 `acc ≈ 0.643`，`macro-F1 ≈ 0.615`。  
   - 产物：`outputs/logs/resnet50_E2.csv`, `outputs/checkpoints/E2_resnet50_no_aug_best.pt`, `outputs/predictions/resnet50_E2_test.csv`。

3. **E3：基础增强对比**  
   - 配置：`--augment basic`（随机翻转、旋转、随机裁剪、ColorJitter，其余同上）。  
   - 结果：验证集 `macro-F1 ≈ 0.661`（最佳 epoch 10），`val_acc ≈ 0.675`；测试集 `acc ≈ 0.650`，`macro-F1 ≈ 0.643`。与 E2 相比，增强策略在验证/测试上均带来 ~3% 的 Macro-F1 提升。  
   - 产物：`outputs/logs/resnet50_E3.csv`, `outputs/checkpoints/E3_resnet50_basic_aug_best.pt`, `outputs/predictions/resnet50_E3_test.csv`。

4. **后续计划**  
   - 依据 E2/E3 结果准备报告中的“数据增强消融”章节，绘制 `val_macro_f1` 对比图。  
   - 选取最佳模型（当前为 E3）生成混淆矩阵、Grad-CAM，可在 `notebooks/30_failure_analysis.ipynb` 中实现。  
   - 视时间继续拓展 E4（ViT/DeiT）或 E6（学习率/优化器消融），并与传统方法团队同步指标表。  

5. **E3 失败样例分析 Notebook 调试**  
   - Notebook：`notebooks/30_failure_analysis.ipynb`。  
   - 修复 `pytorch-grad-cam` 版本差异导致的导入失败与 `GradCAM(..., use_cuda=...)` 废弃参数，确保热力图生成功能可用。  
   - 运行完整流程得到最新的混淆矩阵、失败样例列表与 Grad-CAM 可视化，为解释性分析章节提供素材。  
   - 记录 `torch.load(weights_only=False)` 的安全提醒，后续模型加载将改用 `weights_only=True`。

6. **E4：ViT-B/16 基础增强（Colab GPU）**  
   - 环境：Colab GPU（T4），加载 `PlantDoc_for_colab.zip`，`pip install timm`。  
   - 命令：`python -m src.training.vit_experiment --model vit_base_patch16_224 --augment basic --batch-size 16 --finetune-epochs 20 --lr 5e-5 --device cuda ...`。  
   - 结果：验证集 `macro-F1` 峰值约 **0.724**（epoch 6），`val_acc ≈ 0.728`；早停后测试集 `acc ≈ 0.756`、`macro-F1 ≈ 0.747`。  
   - 产物：`outputs/logs/vit_b16_basic_colab.csv`、`outputs/checkpoints/E4_vit_b16_basic_best.pt`、`outputs/predictions/vit_b16_basic_colab_test.csv`（从 Colab 下载回本地 `outputs/`）。

7. **E5：CLIP ViT-B/32 线性探针（Colab GPU）**  
   - 环境：同上，`pip install git+https://github.com/openai/CLIP.git scikit-learn`。  
   - 命令：`python -m src.training.clip_linear --clip-model "ViT-B/32" --batch-size 64 --epochs 10 --lr 1e-3 --device cuda ...`。  
   - 结果：特征提取 + 线性分类器迭代 10 epoch；验证集 `macro-F1` 最高约 **0.197**，测试集 `acc ≈ 0.344`、`macro-F1 ≈ 0.193`（可作为 LLM/CLIP 基线，说明性能落后于 ResNet/VIT）。  
   - 产物：`outputs/logs/clip_linear_colab.csv`、`outputs/predictions/clip_linear_colab_test.csv`。

8. **E6：超参数/优化器消融（本地 + Colab）**  
   - 新增脚本：`src/training/run_e6_ablation.py`，可一键运行四个实验（或单独运行）。  
   - 共运行四组对照，均在 `--augment basic`、`freeze=5/finetune=15` 下完成：  
     | 实验 | 设置 | 最佳 `val_macro_f1` | 备注 |  
     | --- | --- | --- | --- |  
     | E6-1 | AdamW, lr_head=5e-4, lr_backbone=5e-5 | ~0.651 | 较低 LR，收敛稳定但不及基线 |  
     | E6-2 | AdamW, lr 统一 1e-3 | ~0.498 | 统一 LR 容易震荡，性能下降 |  
     | E6-3 | SGD, lr=3e-3 | ~0.668 | SGD 收敛略慢但最终略优于 E3 |  
     | E6-4 | AdamW, batch size=8 | ~0.652 | 与 batch16 接近，说明批次影响有限 |  
   - 产物：`outputs/logs/E6-*.csv`、`outputs/checkpoints/E6-*_best.pt`、`outputs/predictions/E6-*_test.csv`。  
   - 后续将基于这些日志绘制 “学习率/优化器敏感性” 图表并写入报告。
